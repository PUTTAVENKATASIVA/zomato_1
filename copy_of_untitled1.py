# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xL_rKjAvhghr7lUEyfeSn5GXGGQ_wVmJ

## Data preprocessing
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""## import data"""

data_set=pd.read_csv('Zomato.tsv',delimiter='\t', quoting=3)
print(data_set)
print(data_set.shape)

"""## Cleaning data and stemming

"""

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

corpus=[]
for i in range(0,1000):
  z_re=re.sub('[^a-zA-Z]' ,' ' ,data_set['Review'][i])
  z_re=z_re.lower()
  z_re=z_re.split()
  ps=PorterStemmer()
  all_stopwords=stopwords.words('english')
  all_stopwords.remove('not')
  z_re=[ps.stem(word) for word in z_re if not word in set(all_stopwords)]
  z_re=' '.join(z_re)
  corpus.append(z_re)
print(corpus)

"""## Bag of words"""

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=1600)
x=cv.fit_transform(corpus).toarray()
y=data_set.iloc[:,-1].values

"""## spliting the data set"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)

"""## Traning naive bytes"""

from sklearn.naive_bayes import GaussianNB
cs=GaussianNB()
cs.fit(x_train,y_train)

"""## spliting data"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)

"""## prediction of the test"""

y_pred=cs.predict(x_test)
print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))

"""## feature Scalling"""

from sklearn.metrics import confusion_matrix,accuracy_score
cm=confusion_matrix(y_pred,y_test)
print(cm)
accuracy_score(y_pred,y_test)